{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_DeepFM_test_sourcecode_20200920",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-y8WpISi1GGP",
        "colab_type": "text"
      },
      "source": [
        "FFM 모델을 빌드하기 위해 소스 코드를 뜯어 보자.\n",
        "\n",
        "출처: https://github.com/shenweichen/DeepCTR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIqgc-jhMEHj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모듈 불러오기\n",
        "from itertools import chain\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kMowpwHM23d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 파라미터 설정\n",
        "DEFAULT_GROUP_NAME = \"default_group\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNXNPjCum8a1",
        "colab_type": "text"
      },
      "source": [
        "# utils.py\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAl70IYcy39I",
        "colab_type": "text"
      },
      "source": [
        "## 계산\n",
        "\n",
        " 코드 활용에 필요한 계산(?)들이 정의되어 있다. ~~풀링 모드에 따라서 reduce_sum, reduce_max, reduce_mean 다시 정의한 건가? 왜 굳이 tf 내장 함수 안 쓰고?~~ \n",
        "\n",
        "* ~~reduce_sum~~\n",
        "* ~~reduce_max~~ \n",
        "* ~~div~~\n",
        "* ~~softmax~~\n",
        "* ~~reduce_mean~~"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fssv6HJzm9KY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def reduce_mean(input_tensor, axis=None, keep_dims=False, name=None, reduction_indices=None):\n",
        "    try:\n",
        "        return tf.reduce_mean(input_tensor, axis=axis, keep_dims=keep_dims, name=name, reduction_indices=reduction_indices)\n",
        "    except TypeError:\n",
        "        return tf.reduce_mean(input_tensor, axis=axis, keepdims=keep_dims, name=name)\n",
        "\n",
        "def reduce_sum(input_tensor, axis=None, keep_dims=False, name=None, reduction_indices=None):\n",
        "    try:\n",
        "        return tf.reduce_sum(input_tensor, axis=axis, keep_dims=keep_dims, name=name, reduction_indices=reduction_indices)\n",
        "    except TypeError:\n",
        "        return tf.reduce_sum(input_tensor, axis=axis, keepdims=keep_dims, name=name)\n",
        "\n",
        "def reduce_max(input_tensor, axis=None, keep_dims=False, name=None, reduction_indices=None):\n",
        "    try:\n",
        "        return tf.reduce_max(input_tensor, axis=axis, keep_dims=keep_dims, name=name, reduction_indices=reduction_indices)\n",
        "    except TypeError:\n",
        "        return tf.reduce_max(input_tensor, axis=axis, keepdims=keep_dims, name=name)\n",
        "\n",
        "def div(x, y, name=None):\n",
        "    try:\n",
        "        return tf.div(x, y, name=name)\n",
        "    except AttributeError:\n",
        "        return tf.divide(x, y, name=name)\n",
        "\n",
        "def softmax(logits, dim=-1, name=None):\n",
        "    try:\n",
        "        return tf.nn.softmax(logits, dim=dim, name=name)\n",
        "    except TypeError:\n",
        "        return tf.nn.softmax(logits, axis=dim, name=name)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DrwR-ROyB9f",
        "colab_type": "text"
      },
      "source": [
        "## 레이어 concat, add\n",
        "\n",
        "- concat_func\n",
        "- add_func"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBm1y9sByRmn",
        "colab_type": "text"
      },
      "source": [
        "### concat, add를 위한 클래스"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGfA_fxbyG0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "class Add(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(Add, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        super(Add, self).build(input_shape) # call해야 함.\n",
        "\n",
        "    def call(self, inputs, **kwargs):\n",
        "        if not isinstance(inputs, list):\n",
        "            return inputs\n",
        "        if len(inputs) == 1:\n",
        "            return inputs[0]\n",
        "        if len(inputs) == 0:\n",
        "            return tf.constant([[0.0]])\n",
        "\n",
        "        return tf.keras.layers.add(inputs)\n",
        "\n",
        "\n",
        "class NoMask(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(NoMask, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Be sure to call this somewhere!\n",
        "        super(NoMask, self).build(input_shape)\n",
        "\n",
        "    def call(self, x, mask=None, **kwargs):\n",
        "        return x\n",
        "\n",
        "    def compute_mask(self, inputs, mask):\n",
        "        return None"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHtdbEv_ygUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_func(inputs):\n",
        "    return Add()(inputs)\n",
        "\n",
        "def concat_func(inputs, axis=-1, mask=False):\n",
        "    if not mask:\n",
        "        inputs = list(map(NoMask(), inputs))\n",
        "    if len(inputs) == 1:\n",
        "        return inputs[0]\n",
        "    else:\n",
        "        return tf.keras.layers.Concatenate(axis=axis)(inputs)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6P0KGHXJy8_M",
        "colab_type": "text"
      },
      "source": [
        "## combinde_dnn_input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALIpi7K1zF-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Concatenate\n",
        "\n",
        "\n",
        "def combined_dnn_input(sparse_embedding_list, dense_value_list):\n",
        "    if len(sparse_embedding_list) > 0 and len(dense_value_list) > 0:\n",
        "        sparse_dnn_input = Flatten()(concat_func(sparse_embedding_list))\n",
        "        dense_dnn_input = Flatten()(concat_func(dense_value_list))\n",
        "        return concat_func([sparse_dnn_input, dense_dnn_input])\n",
        "    elif len(sparse_embedding_list) > 0:\n",
        "        return Flatten()(concat_func(sparse_embedding_list))\n",
        "    elif len(dense_value_list) > 0:\n",
        "        return Flatten()(concat_func(dense_value_list))\n",
        "    else:\n",
        "        raise NotImplementedError(\"dnn_feature_columns가 비어 있으면 안 됨.\")"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBm0_U9ikJpI",
        "colab_type": "text"
      },
      "source": [
        "# Layer 종류 class\n",
        "\n",
        "- sequence: SequencePoolingLayer, WeightedSequenceLayer\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaawiVIMkc13",
        "colab_type": "text"
      },
      "source": [
        "## SequencePoolingLayer\n",
        "\n",
        "> 원래 layers.sequence에 있음.\n",
        "\n",
        " Keras layer를 상속받는다. 가변 길이의 sequence나 multi-value 피쳐에 대해 sum, mean, max 풀링 연산을 한다. \n",
        " \n",
        "1. Input: [seq_value, seq_len] : sequence의 value와 길이를 나타내는 ??두 텐서의 리스트\n",
        "    - seq_value : `(batch_size, T, embedding_size)`\n",
        "    - seq_len : `(batch_size, 1)`\n",
        "\n",
        "2. Output: `(batch_size, 1, embedding_size)`의 3D tensor\n",
        "    - 풀링연산 한 뒤 3차원으로 바꾼 것인가??\n",
        "\n",
        "3. Arguments\n",
        "    - mode: 풀링 연산 종류(mean, max, sum)\n",
        "    - supports_masking: `True`일 경우, 마스킹 가능해야 함.\n",
        "\n",
        "<br>\n",
        "\n",
        " masking 가능 여부에 따라서 달라진다. masking support할 거면 직접 mask 만들어주고 차원 확장해주고, 그게 아니면 인자로 받은 것에서 tensorflow 내장 함수 이용해서 sequence_mask 만들고 축만 바꿔주면 되는 듯. tile 함수 통해서 마스킹하는 과정은 기존에 살펴 본 마스킹과 동일. 0에 가까운 수를 곱해서 빼준다.\n",
        "\n",
        "<br>\n",
        "\n",
        " 축 확장해서 3차원으로!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2kJd-jQkOsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Layer\n",
        "import tensorflow as tf\n",
        "\n",
        "class SeuqencePoolingLayer(Layer):\n",
        "\n",
        "    def __init__(self, mode='mean', supports_masking=False, **kwargs):\n",
        "\n",
        "        if mode not in ['sum', 'mean', 'max']:\n",
        "            raise ValueError(\"풀링 연산은 sum, mean, max 중 하나여야 함.\")\n",
        "        self.mode = mode\n",
        "        self.eps = tf.constant(1e-8, dtype=tf.float32)\n",
        "        super(SequencePoolingLayer, self).__init__(**kwargs)\n",
        "        \n",
        "        self.supports_masking = supports_masking\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        if not self.supports_masking:\n",
        "            self.seq_len_max = int(input_shape[0][1])\n",
        "        super(SequencePoolingLayer, self).build(input_shape) # call해야 함에 주의.\n",
        "    \n",
        "    def call(self, seq_value_len_list, mask=None ,**kwargs):\n",
        "        if self.supports_masking:\n",
        "            if mask is None:\n",
        "                raise ValueError(\"supports_masking 옵션이 True일 때는 input이 masking가능해야 함.\")\n",
        "            uiseq_embed_list = seq_value_len_list\n",
        "            mask = tf.cast(mask, dtype=tf.float32) # tf.to_float(mask)\n",
        "            use_behavior_length = reduce_sum(mask, axis=-1, keep_dims=True)\n",
        "            mask = tf.expand_dims(mask, axis=2)\n",
        "        else:\n",
        "            uiseq_embed_list, user_behavior_length = seq_value_len_list\n",
        "            mask = tf.sequence_mask(user_behavior_length, self.seq_len_max, dtype=tf.float32)\n",
        "        \n",
        "        embedding_size = uiseq_embed_list.shape[-1]\n",
        "        mask = tf.tile(mask, [1, 1, embedding_size])\n",
        "\n",
        "        if self.mode == 'max':\n",
        "            hist = uiseq_embed_list - (1-mask) * 1e9\n",
        "            return reduce_max(hist, 1, keep_dims=True)\n",
        "        \n",
        "        if self.mode == 'mean':\n",
        "            hist = div(hist, tf.cast(user_behavior_length, dtype=tf.foat32) + self.eps)\n",
        "        \n",
        "        hist = tf.expand_dims(hist, axis=1)\n",
        "        return hist\n",
        "    \n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if self.supports_masking:\n",
        "            return (None, 1, input_shape[-1])\n",
        "        else:\n",
        "            return (None, 1, input_shape[0][-1])\n",
        "    \n",
        "    def compute_mask(self, inputs, mask):\n",
        "        return None\n",
        "    \n",
        "    def get_config(self, ):\n",
        "        config = {'mode': self.mode,\n",
        "                  'supports_masking': self.supports_masking}\n",
        "        base_config = super(SequencePoolingLayer, self).get_config()\n",
        "        return dict(list(base_config.items())) + list(config.items())"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FxHjt0OqdDj",
        "colab_type": "text"
      },
      "source": [
        "## WeightedSequenceLayer\n",
        "\n",
        "> 원래 layers.sequence에 있음.\n",
        "\n",
        "\n",
        " Keras layer를 상속받는다. 가변 길이의 sequence나 multi-value 피쳐에 대해 weight score를 적용한다.\n",
        " \n",
        "1. Input: [seq_value, seq_len, seq_weight] : sequence의 value와 길이, weight를 나타내는 세 텐서의 리스트.\n",
        "    - seq_value: `(batch_size, T, embedding_size)`\n",
        "    - seq_len: `(batch_size, 1)`\n",
        "    - seq_weight: `(batch_size, T, 1)`\n",
        "\n",
        "2. Output: `(batch_size, 1, embedding_size)`의 3D tensor\n",
        "    - 풀링연산 한 뒤 3차원으로 바꾼 것인가??\n",
        "\n",
        "3. Arguments\n",
        "    - weight_normalization: weight 적용 전에 normalize할 것인지 여부.\n",
        "    - supports_masking: `True`일 경우, 마스킹 가능해야 함.\n",
        "\n",
        "<br>\n",
        "\n",
        " masking 가능 여부, weight_normalization 여부에 따라서 달라진다. weight_normalization은 softmax. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9g6ES1vKqc7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WeightedSequenceLayer(Layer):\n",
        "\n",
        "    def __init__(self, weight_normalization=True, supports_masking=False, **kwargs):\n",
        "        super(WeightedSequenceLayer, self).__init__(**kwargs)\n",
        "        self.weight_normalization = weight_normalization\n",
        "        self.supports_masking = supports_masking\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if not self.supports_masking:\n",
        "            self.seq_len_max = int(input_shape[0][1])\n",
        "        super(WeightedSequenceLayer, self).build(input_shape) # call해야 함에 주의.\n",
        "\n",
        "    def call(self, input_list, mask=None, **kwargs):\n",
        "        if self.supports_masking:\n",
        "            if mask is None:\n",
        "                raise ValueError(\"supports_masking 옵션이 True일 때는 input이 masking가능해야 함.\")\n",
        "            key_input, value_input = input_list\n",
        "            mask = tf.expand_dims(mask[0], axis=2)\n",
        "        else:\n",
        "            key_input, key_length_input, value_input = input_list\n",
        "            mask = tf.sequence_mask(key_length_input, self.seq_len_max, dtype=tf.bool)\n",
        "            mask = tf.transpose(mask, (0, 2, 1))\n",
        "\n",
        "        embedding_size = key_input.shape[-1]\n",
        "\n",
        "        if self.weight_normalization:\n",
        "            paddings = tf.ones_like(value_input) * (-2 ** 32 + 1)\n",
        "        else:\n",
        "            paddings = tf.zeros_like(value_input)\n",
        "        value_input = tf.where(mask, value_input, paddings)\n",
        "\n",
        "        if self.weight_normalization:\n",
        "            value_input = softmax(value_input, dim=1)\n",
        "\n",
        "        if len(value_input.shape) == 2:\n",
        "            value_input = tf.expand_dims(value_input, axis=2)\n",
        "            value_input = tf.tile(value_input, [1, 1, embedding_size])\n",
        "\n",
        "        return tf.multiply(key_input, value_input)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0]\n",
        "\n",
        "    def compute_mask(self, inputs, mask):\n",
        "        if self.supports_masking:\n",
        "            return mask[0]\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def get_config(self, ):\n",
        "        config = {'weight_normalization': self.weight_normalization, \n",
        "                  'supports_masking': self.supports_masking}\n",
        "        base_config = super(WeightedSequenceLayer, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0HShVZozjPh",
        "colab_type": "text"
      },
      "source": [
        "##  FM Layer\n",
        "\n",
        "> 원래 layers.interaction에 있음.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TobYhkqezlHX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "\n",
        "class FM(Layer):\n",
        "    \n",
        "    def __init__(self, **kwargs):\n",
        "        super(FM, self).__init__(**kwargs)\n",
        "    \n",
        "    def build(self, input_shape):\n",
        "        if len(input_shape) != 3:\n",
        "            raise ValueError(\"차원이 맞지 않음: %d, \\\n",
        "                              3차원이어야 함\" % (len(input_shape)))\n",
        "        super(FM, self).build(input_shape) # call해야 함.\n",
        "\n",
        "'''\n",
        "여기서부터 다시!\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrgjNjMOQrzJ",
        "colab_type": "text"
      },
      "source": [
        "# Feature 종류 class\n",
        "\n",
        "\n",
        "1. SparseFeat\n",
        "    - int형이어야 함.\n",
        "\n",
        "2. DenseFeat\n",
        "    - float형이어야 함.\n",
        "\n",
        "3. VarLenSparseFeat\n",
        "    - ~~프로퍼티 속성 변경해야 하므로 속성 접근 정의해 놓은 듯.~~ 잉 아닌디?\n",
        "    - "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYTddXkENtKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import namedtuple\n",
        "from tensorflow.keras.initializers import RandomNormal, Zeros\n",
        "\n",
        "\n",
        "class SparseFeat(namedtuple('SparseFeat',\n",
        "                            ['name', 'vocabulary_size', 'embedding_dim', 'use_hash', 'dtype',\n",
        "                             'embeddings_initializer', 'embedding_name', 'group_name', \n",
        "                             'trainable'])):\n",
        "    __slots__ = ()\n",
        "\n",
        "    def __new__(cls, name, vocabulary_size, embedding_dim=4, use_hash=False, dtype='int32',\n",
        "                embeddings_initializer=None, embedding_name=None, group_name=DEFAULT_GROUP_NAME,\n",
        "                trainable=False):        \n",
        "\n",
        "        print(\"SparseFeat, __new__ 메소드 호출\")\n",
        "\n",
        "        if embedding_dim == 'auto':\n",
        "            embedding_dim = 6 * int(pow(vocabulary_size, 0.25))\n",
        "        if embedding_initializer is None:\n",
        "            embeddings_initializer = RandomNormal(mean=0.0, stdev=0.0001, seed=2020)\n",
        "        if embedding_name is None:\n",
        "            embedding_name = name\n",
        "        \n",
        "        return super(SparseFeat, cls).__new__(cls, name, vocabulary_size, embedding_dim, use_hash, dtype,\n",
        "                                              embeddings_initializer, ebedding_name, group_name,\n",
        "                                              trainable)\n",
        "        \n",
        "    def __hash__(self):\n",
        "        return self.name.__hash__()\n",
        "\n",
        "\n",
        "class DenseFeat(namedtuple('DenseFeat',\n",
        "                           ['name', 'dimension', 'dtype'])):\n",
        "    __slots__ = ()\n",
        "\n",
        "    def __new__(cls, name, dimension=1, dtype='float32'):\n",
        "        return super(DenseFeat, cls).__new__(cls, name, dimension, dtype)\n",
        "    \n",
        "    def __hash__(self):\n",
        "        return self.name.__hash__()\n",
        "\n",
        "\n",
        "class VarLenSparseFeat(namedtuple('VarLenSparseFeat',\n",
        "                                  ['sparsefeat', 'maxlen', 'combiner', 'length_name', 'weight_name', 'weight_norm'])):\n",
        "    __slots__ = ()\n",
        "\n",
        "    def __new__(cls, sparsefeat, maxlen, combiner='mean', length_name=None, weight_name=None, weight_norm=True):\n",
        "        return super(VarLenSparseFeat, cls).__new__(cls, sparsefeat, maxlen, combiner, length_name, weight_name, weight_norm)\n",
        "\n",
        "    @property\n",
        "    def name(self):\n",
        "        return self.sparsefeat.name\n",
        "\n",
        "    @property\n",
        "    def vocabulary_size(self):\n",
        "        return self.sparsefeat.vocabulary_size\n",
        "    \n",
        "    @property\n",
        "    def embedding_dim(self):\n",
        "        return self.sparsefeat.embedding_dim\n",
        "    \n",
        "    @property\n",
        "    def use_hash(self):\n",
        "        return self.sparsefeat.use_hash\n",
        "    \n",
        "    @property\n",
        "    def dtype(self):\n",
        "        return self.sparsefeat.dtype\n",
        "    \n",
        "    @property\n",
        "    def dtype(self):\n",
        "        return self.sparsefeat.dtype\n",
        "    \n",
        "    @property\n",
        "    def embeddings_initializer(self):\n",
        "        return self.sparsefeat.embeddings_initializer\n",
        "    \n",
        "    @property\n",
        "    def embedding_name(self):\n",
        "        return self.sparsefeat.embedding_name\n",
        "    \n",
        "    @property\n",
        "    def group_name(self):\n",
        "        return self.sparsefeat.group_name\n",
        "    \n",
        "    @property\n",
        "    def trainable(self):\n",
        "        return self.sparsefeat.trainable\n",
        "    \n",
        "    def __hash__(self):\n",
        "        return self.name.__hash__()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e7O-RkIQmJT",
        "colab_type": "text"
      },
      "source": [
        "# Input Feature building\n",
        "\n",
        "- sparsefeat, densefeat, varlensparsefeat인지에 따라서 input feature 빌딩 방법이 다르다.\n",
        "    - 가변 길이 sparse인 경우, max 길이에 맞춤.\n",
        "    - batch_shape으로 바꿀 수 없는지 확인."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsdmQ4KkP_uy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import OrderedDict\n",
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "\n",
        "def build_input_features(feature_columns, prefix=''):\n",
        "    input_features = OrderedDict()\n",
        "    for fc in feature_columns:\n",
        "        if isinstance(fc, SparseFeat):\n",
        "            input_features[fc.name] = Input(shape=(1, ), name=prefix+fc.name, dtype=fc.dtype)\n",
        "        elif isinstance(fc, DenseFeat):\n",
        "            input_features[fc.name] = Input(shape=(fc.dimension, ), name=prefix+fc.name, dtype=fc.dtype)\n",
        "        elif isinstance(fc, VarLenSparseFeat):\n",
        "            input_features[fc.name] = Input(shape=(fc.maxlen,), name=prefix+fc.name, dtype=fc.dtype)\n",
        "            if fc.weight_name is not None:\n",
        "                input_features[fc.weight_name] = Input(shape=(fc.maxlen, 1), name=prefix+fc.weight_name, dtype='float32')\n",
        "            if fc.length_name is not None:\n",
        "                input_features[fc.length_name] = Input(shape=(1, ), name=prefix+fc.length_name, dtype='int32')\n",
        "        else:\n",
        "            raise TypeError(\"Feature Column 오류. 현재 Feature Column Type: {}\".shape(type(fc)))\n",
        "    return input_features"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qocSbRkza05r",
        "colab_type": "text"
      },
      "source": [
        "# feature column으로부터 input 만들기\n",
        "\n",
        " `inputs.py`에 정의되어 있는 함수들을 이용해서 input 값을 만든다.\n",
        "\n",
        "\n",
        "\n",
        "- filter를 통해 각 column이 어디에 속하는지 확인한 후 list로 반환. 단, feature_columns 인자 없으면 빈 리스트.\n",
        "- embedding matrix를 `create_embedding_matrix` 함수를 가지고 만든 후,\n",
        "- embedding_lookup을 통해 위에서 만든 dictionary에서 feature의 embedding을 찾는다. 그런데 이건 sparse feature에 대해서만.\n",
        "- dense feature에 대해서는 get_dense_input한 뒤, 위와 비슷한 방식으로 함수들을 이용해서 embedding matrix 만들고 찾고.\n",
        "- 만약에 dense support하지 않는데 dense column 있다면 잘못한 것이므로 오류.\n",
        "- 마지막에 mergeDict로 다 합친다. 그런데 그룹핑하지 않으려면 chain해서 flatten."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AFLWQXWcoJw",
        "colab_type": "text"
      },
      "source": [
        "## inputs.py\n",
        "\n",
        " 인풋값 만드는 데 필요한 함수들 정의되어 있다.\n",
        "\n",
        "- ~~`create_embedding_dict`~~\n",
        "- ~~`create_embeding_matrix`~~\n",
        "- ~~`embedding_lookup`~~\n",
        "- ~~`get_dense_input`~~\n",
        "- ~~`varlen_embedding_lookup`~~\n",
        "- ~~`get_varlen_pooling_list`~~\n",
        "- ~~`mergeDict`~~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IMt-347erk5",
        "colab_type": "text"
      },
      "source": [
        "### create_embedding_dict\n",
        "\n",
        " sparse feature와 varlen sparse feature에 대해서 임베딩을 만든다. 케라스 임베딩 레이어이고, input_dim, output_dim은 feature에서 애초에 설정되어 있고, trainable 여부는 feature에서 trainable 설정한 여부와 동일하다. 딕셔너리에 임베딩 레이어를 설정해서 저장한다.\n",
        "\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QP595X-eAa7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "\n",
        "def create_embedding_dict(sparse_feature_columns, varlen_sparse_feature_columns, seed, l2_reg,\n",
        "                          prefix='sparse_', seq_mask_zero=True):\n",
        "    sparse_embedding = {}\n",
        "    for feat in sparse_feature_columns:\n",
        "        emb = Embedding(feat.vocabulary_size, feat.embedding_dim,\n",
        "                        embeddings_initializer=feat.embeddings_initializer,\n",
        "                        embeddings_regularizer=l2(l2_reg),\n",
        "                        name=prefix+'_emb_'+feat.embedding_name)\n",
        "        emb.trainable = feat.trainable\n",
        "        sparse_embedding[feat.embedding_name] = emb\n",
        "    \n",
        "    if varlen_sparse_feature_columns and len(varlen_sparse_feature_columns) > 0:\n",
        "        for feat in varlen_sparse_feature_columns:\n",
        "            emb = Embedding(feat.vocabulary_size, feat.embedding_dim,\n",
        "                            embeddings_initializer=feat.embeddings_initializer,\n",
        "                            embeddings_regularizer=l2(l2_reg),\n",
        "                            name=prefix+'_seq_emb_'+feat.name,\n",
        "                            mask_zero=seq_mask_zero)\n",
        "            emb.trainable = feat.trainable\n",
        "            sparse_embedding[feat.embedding_name] = emb\n",
        "    return sparse_embedding"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUtCBn8LjIuI",
        "colab_type": "text"
      },
      "source": [
        "### create_embedding_matrix\n",
        "\n",
        "- `feature_column`에 정의되어 있는 클래스들 활용한다. \n",
        "- 일단 지금은 노트북이므로 import 안 해도 되는 것으로.\n",
        "- 원래는 아래처럼 써야 한다.\n",
        "```\n",
        "from . import feature_column as fc_lib\n",
        "\n",
        "    sparse_feature_columns = list(\n",
        "    filter(lambda x: isinstance(x, fc_lib.SparseFeat), feature_columns)) if feature_columns else []\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "su55ThPwcrYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_embedding_matrix(feature_columns, l2_reg, seed, prefix='', seq_mask_zero=True):\n",
        "    sparse_feature_columns = list(\n",
        "        filter(lambda x: isinstance(x, SparseFeat), feature_columns)) if feature_columns else []\n",
        "    varlen_sparse_feature_columns = list(\n",
        "        filter(lambda x: isinstance(x, VarLenSparseFeat), feature_columns)) if feature_columns else []\n",
        "    sparse_emb_dict = create_embedding_dict(sparse_features, varlen_sparse_feature_columns, seed,\n",
        "                                            l2_reg, prefix=prefix + 'sparse', seq_mask_zero=seq_mask_zero)\n",
        "    return sparse_emb_dict"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YRntXyLhUT1",
        "colab_type": "text"
      },
      "source": [
        "### embedding_lookup / varlen_embedding_lookup\n",
        "\n",
        " hash 혹은 feauture name 사용해서 embedding을 찾는다.\n",
        "\n",
        " - embedding_lookup은 defaultdict 해서 list flatten하고."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ph0U5KKOgie4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "from itertools import chain\n",
        "\n",
        "\n",
        "def embedding_lookup(spasre_embedding_dict, sparse_input_dict, sparse_feature_columns, return_feat_list=(), \n",
        "                     mask_feat_list=(), to_list=False):\n",
        "    group_embedding_dict=defaultdict(list)\n",
        "    for fc in sparse_feature_columns:\n",
        "        feature_name = fc.name\n",
        "        embedding_name = fc.embedding_name\n",
        "        if (len(return_feat_list) == 0 or feature_name in return_feat_list):\n",
        "            if fc.use_hash:\n",
        "                lookup_idx = Hash(fc.vocabulary_size, mask_zero=(feature_name in mask_feat_list))(\n",
        "                    sparse_input_dict[feature_name])\n",
        "            else:\n",
        "                lookup_idx = sparse_input_dict[feature_name]\n",
        "            \n",
        "            group_emgedding_dict[fc.group_name].append(spasre_embedding_dict[embedding_name](lookup_idx))\n",
        "        if to_list:\n",
        "            return list(chain.from_iterable(group_embedding_dict.value()))\n",
        "        return group_embedding_dict"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN6p8XUqgiWc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def varlen_embedding_lookup(embedding_dict, sequence_input_dict, varlen_sparse_feature_columns):\n",
        "    varlen_embedding_vec_dict = {}\n",
        "    for fc in varlen_sparse_feature_columns:\n",
        "        feature_name = fc.name\n",
        "        embedding_name = fc.embedding_name\n",
        "        if fc.use_hash:\n",
        "            lookup_idx = Hash(fc.vocabulary_size, mask_zero=True)(sequence_input_dict[feature_name])\n",
        "        else:\n",
        "            lookup_idx = sequence_input_dict[feature_name]\n",
        "        varlen_embedding_vec_dict[feature_name] = embedding_dict[embedding_name](lookup_idx)\n",
        "    return varlen_embedding_vec_dict"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lz_-y-KHjBSo",
        "colab_type": "text"
      },
      "source": [
        "### get_dense_input\n",
        "\n",
        "\n",
        "- `feature_column`에 정의되어 있는 클래스들 활용한다. \n",
        "- 일단 지금은 노트북이므로 import 안 해도 되는 것으로.\n",
        "- 원래는 아래처럼 써야 한다.\n",
        "```\n",
        "from . import feature_column as fc_lib\n",
        "\n",
        "    sparse_feature_columns = list(\n",
        "    filter(lambda x: isinstance(x, fc_lib.DenseFeat), feature_columns)) if feature_columns else []\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpT5AymVi8OU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_dense_input(features, feature_columns):\n",
        "    dense_feature_columns = list(\n",
        "        filter(lambda x: isinstance(x, DenseFeat), feature_columns)) if feature_columns else []\n",
        "    dense_input_list = [features[fc.name] for fc in dense_feature_columns]\n",
        "    return dense_input_list"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9HymcY3jscL",
        "colab_type": "text"
      },
      "source": [
        "### get_varlen_pooling_list\n",
        "\n",
        " 가변 길이 sequence 풀링해서 리스트를 반환한다.\n",
        "\n",
        " - weight_name 있으면 WeightedSequenceLayer 사용하고,\n",
        " - weight_name 없으면 weight 안 주는 거로 생각해서 embedding 사용하는데,\n",
        "<br>\n",
        "\n",
        " 그렇게 해서 SequencePoolingLayer로 간다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RK7OqzuzjxaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "def get_varlen_pooling_list(embedding_dict, features, varlen_sparse_columns, to_list=False):\n",
        "    pooling_vec_list = defaultdict(list)\n",
        "    for fc in varlen_sparse_columns:\n",
        "        feature_name = fc.name\n",
        "        combiner = fc.combiner\n",
        "        feature_length_name = fc.feature_length_name\n",
        "        if feature_length_name is not None:\n",
        "            if fc.weight_name is not None:\n",
        "                seq_input = WeightedSequenceLayer(weight_normalization=fc.weight_norm)(\n",
        "                    [embedding_dict[feature_name], features[feature_length_name], features[fc.weight_name]])\n",
        "            else:\n",
        "                seq_input = embedding_dict[feature_name]\n",
        "            vec = SeuqencePoolingLayer(combinder, supports_masking=False)(\n",
        "                [seq_input, features[feature_length_name]])\n",
        "        else:\n",
        "            if fc.weight_name is not None:\n",
        "                seq_input = WeightedSequenceLayer(weight_normalization=fc.weight_norm, supports_masking=True)(\n",
        "                    [embedding_dict[feature_name], features[fc.weight_name]])\n",
        "            else:\n",
        "                seq_input = embedding_dict[feature_name]\n",
        "            vec = SequencePoolingLayer(combinder, supports_masking=True)(seq_input)\n",
        "        \n",
        "        pooling_vec_list[fc.group_name].append(vec)\n",
        "        \n",
        "    if to_list:\n",
        "        return chain.from_iterable(pooling_vec_list.values())\n",
        "    return pooling_vec_list"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6IDWzczwEiq",
        "colab_type": "text"
      },
      "source": [
        "### mergeDict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxbMOTQ9wFxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "def mergeDict(a, b):\n",
        "    c = defaultdict(list)\n",
        "    for k, v in a.items():\n",
        "        c[k].extend(v)\n",
        "    for k, v in b.items():\n",
        "        c[k].extend(v)\n",
        "    return c"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLnPJac5c6MP",
        "colab_type": "text"
      },
      "source": [
        "## 다시 input 만들기로 돌아 와서.\n",
        "\n",
        " 임베딩된 것을 합친다. 만약에 그룹핑 허용하지 않으면, flatten하여 리스트로 반환한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlQ3CmyDa35F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def input_from_feature_columns(features, feature_columns, l2_reg, seed, prefix='', seq_mask_zero=True,\n",
        "                               support_dense=True, support_group=False):\n",
        "    \n",
        "    sparse_feature_columns = list(\n",
        "        filter(lambda x: isinstance(x, SparseFeat), feature_columns)) if feature_columns else []\n",
        "    varlen_sparse_feature_columns = list(\n",
        "        filter(lambda x: isinstance(x, VarLenSparseFeat), feature_columns)) if feature_columns else []\n",
        "    \n",
        "    embedding_matrix_dict = create_embedding_matrix(feature_colums, l2_reg, seed, prefix=prefix, \n",
        "                                                    seq_mask_zero=seq_mask_zero)\n",
        "\n",
        "    group_sparse_embedding_dict = embedding_lookup(embedding_matrix_dict, features, sparse_feature_columns)\n",
        "    dense_value_list = get_dense_input(features, feature_columns)\n",
        "\n",
        "    if not support_dense and len(dense_value_list) > 0:\n",
        "        raise ValueError(\"DenseFeature DNN에서 사용할 수 없음.\")\n",
        "    \n",
        "    seq_embed_dict = varlen_embedding_lookup(embedding_matrix_dict, features, varlen_sparse_feature_columns)\n",
        "    group_varlen_sparse_embedding_dict = get_varlen_pooling_list(sequence_embed_dict, features,\n",
        "                                                                 varlen_sparse_feature_columns)\n",
        "    group_embedding_dict = mergeDict(group_sparse_embedding_dict, group_varlen_sparse_embedding_dict)\n",
        "    if not support_group:\n",
        "        group_embedding_dict = list(chain.from_iterable(group_embedding_dict.values()))\n",
        "    return group_embedding_dict, dense_value_list"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1OgW9_jYs3V",
        "colab_type": "text"
      },
      "source": [
        "# linear 로짓 계산\n",
        "\n",
        "- deepcopy 안 해도 되는지?\n",
        "- `_replace`로 namedtuple 프로퍼티 변경\n",
        "- 프로퍼티 바꾸고 할당해야 하므로 enumerate 안 될 듯."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqlphNjGYvh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_linear_logit(features, feature_columns, units=1, use_bias=False, seed=1024, prefix='linear', l2_reg=0):\n",
        "    linear_feature_columns = copy(feature_columns)\n",
        "    for i in range(len(linear_feature_columns)):\n",
        "        if isinstance(linear_feature_columns[i], SparseFeat):\n",
        "            linear_feature_columns[i] = linear_feature_columns[i]._replace(embedding_dim=1, \n",
        "                                                                           embeddings_initializer=Zeros())\n",
        "        if isinstance(linear_feature_columns[i], VarLenSparseFeat):\n",
        "            linear_feature_columns[i] = linear_feature_columns[i]._replace(embedding_dim=1,\n",
        "                                                                           embedidngs_initializer=Zeros())\n",
        "    \n",
        "    linear_emb_list = [input_from_feature_columns(\n",
        "\n",
        "        '''\n",
        "        여기 채워야 합니다.\n",
        "        '''\n",
        "\n",
        "    )]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3R-F3qnWKP-",
        "colab_type": "text"
      },
      "source": [
        "# DeepFM 모델 빌드\n",
        "\n",
        "1. 파라미터\n",
        "    - `linear_feature_columns`: linear part에 사용될 feature들의 이터러블.\n",
        "    - `dnn_feature_columns`: deep part에 사용될 feature들의 이터러블.\n",
        "    - `fm_group`: feature 상호작용에 사용될 feature들의 리스트와 그것의 그룹 이름(지정하면 되나?)\n",
        "    - `dnn_hidden_units`: DNN 각각의 레이어에 사용될 layer number, units의 리스트(각각은 양수이거나 빈 리스트여야 함).\n",
        "    - `l2_reg_linear`: 실수. linear part에 적용될 L2 규제항.\n",
        "    - `l2_reg_embeddng`: 실수. embedding vector에 적용할 L2 규제항.\n",
        "    - `l2_reg_dnn`: 실수. DNN에 적용할 L2 규제항.\n",
        "    - `seed`: 시드값.\n",
        "    - `dnn_dropout`: DNN 네트워크 노드 드롭아웃 비율.\n",
        "    - `dnn_activation`: DNN 활성화 함수.\n",
        "    - `dnn_use_bn`: DNN에서 배치 노멀라이제이션 여부.\n",
        "    - `task`: binary(binary logloss), regression(regression loss)\n",
        "\n",
        "2. 리턴 : 케라스 모델 객체."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2masV2XXuZq",
        "colab_type": "text"
      },
      "source": [
        "* linear column, dnn column 리스트로 받아서, input feature 빌드한다.\n",
        "* ordered dictionary 반환되는데, 거기서 values만 받아 리스트로 만든다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNseMZoOYkeg",
        "colab_type": "text"
      },
      "source": [
        "## feature_column\n",
        "\n",
        "- ~~build_input_features~~\n",
        "- ~~get_linear_logit~~\n",
        "- ~~DEFAULT_GROUP_NAME~~\n",
        "- ~~input_from_feature_columns~~\n",
        "\n",
        "## layers.core\n",
        "- PredictionLayer\n",
        "- DNN\n",
        "\n",
        "## layers.interaction\n",
        "- ~~FM~~\n",
        "\n",
        "## layers.utils\n",
        "- ~~concat_func~~\n",
        "- ~~add_func~~\n",
        "- ~~combined_dnn_input~~"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3TjFEr_Mxwd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모델 빌드 함수\n",
        "def DeepFM(linear_feature_columns, dnn_feature_columns, fm_group=[DEFAULT_GROUP_NAME], dnn_hidden_units=(128, 128),\n",
        "           l2_reg_linear=0.00001, l2_reg_embedding=0.00001, l2_reg_dnn=0, seed=1024, dnn_dropout=0,\n",
        "           dnn_activation='relu', dnn_use_bn=False, task='binary'):\n",
        "    features = build_input_features(linear_feature_columns + dnn_feature_columns)\n",
        "    inputs_list = list(features.values())\n",
        "    linear_logit = get_linear_logit(features, linear_feature_columns, seed=seed, prefix='linear',\n",
        "                                    l2_reg=l2_reg_linear)\n",
        "    group_embedding_dict, dense_value_list = input_from_feature_columns(features, dnn_feature_columns, l2_reg_embedding,\n",
        "                                                                        seed, support_group=True)\n",
        "    \n",
        "    fm_logit = add_func()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJbPxRNGYWya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J--FeFTPYXBS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxQbNurqYXPD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGRiQmJGYXG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dR_w4ucyYW3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxihFhGtYWoG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}